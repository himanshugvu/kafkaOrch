version: "3.9"

services:
  kafka:
    image: bitnami/kafka:3.7.0
    ports:
      - "9094:9094"
    environment:
      - KAFKA_ENABLE_KRAFT=yes
      - KAFKA_CFG_NODE_ID=1
      - KAFKA_CFG_PROCESS_ROLES=broker,controller
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://:9094
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092,EXTERNAL://localhost:9094
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka:9093
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
      - KAFKA_CFG_NUM_PARTITIONS=3
      - KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR=1
      - KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
      - ALLOW_PLAINTEXT_LISTENER=yes
    volumes:
      - kafka_data:/bitnami/kafka
    healthcheck:
      test: ["CMD", "/opt/bitnami/kafka/bin/kafka-topics.sh", "--bootstrap-server", "localhost:9092", "--list"]
      interval: 10s
      timeout: 5s
      retries: 10

  postgres:
    image: postgres:16
    environment:
      - POSTGRES_DB=orch
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d orch"]
      interval: 10s
      timeout: 5s
      retries: 10

  orders-orchestrator:
    build: .
    depends_on:
      kafka:
        condition: service_healthy
      postgres:
        condition: service_healthy
      logstash:
        condition: service_started
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      JDBC_URL: jdbc:postgresql://postgres:5432/orch?reWriteBatchedInserts=true
      JDBC_USER: postgres
      JDBC_PASSWORD: postgres
      SOURCE_TOPIC: orders.raw
      TARGET_TOPIC: orders.enriched
      GROUP_ID: orders-orchestrator
      DB_STRATEGY: RELIABLE
      LOGGING_LOGSTASH_DESTINATION: ${LOGGING_LOGSTASH_DESTINATION:-logstash:5044}
    ports:
      - "8080:8080"

  locust:
    image: locustio/locust:2.26.0
    profiles: ["load"]
    depends_on:
      orders-orchestrator:
        condition: service_started
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      LOCUST_PRODUCER_TOPIC: orders.raw
      LOCUST_CONSUMER_TOPIC: orders.enriched
      LOCUST_GROUP_ID: locust-verify
      LOCUST_TARGET_MESSAGES: 1000000
      LOCUST_TEST_ID: bootstrap-locust
      LATENCY_OUTPUT: /mnt/locust/reports/latency_samples.csv
    volumes:
      - ./load-test:/mnt/locust
      - ./reports:/mnt/locust/reports
    working_dir: /mnt/locust
    command: >-
      -f locustfile.py --headless -u 50 -r 5 --stop-timeout 300 --csv=/mnt/locust/reports/locust

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.13
    environment:
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
    ports:
      - "9200:9200"
    volumes:
      - es_data:/usr/share/elasticsearch/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9200/_cluster/health"]
      interval: 20s
      timeout: 10s
      retries: 10

  logstash:
    image: docker.elastic.co/logstash/logstash:7.17.13
    depends_on:
      elasticsearch:
        condition: service_healthy
    ports:
      - "5044:5044"
      - "9600:9600"
    volumes:
      - ./observability/logstash/pipeline:/usr/share/logstash/pipeline
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9600/_node/pipelines"]
      interval: 20s
      timeout: 10s
      retries: 10

  kibana:
    image: docker.elastic.co/kibana/kibana:7.17.13
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"
    depends_on:
      elasticsearch:
        condition: service_healthy

volumes:
  kafka_data:
  postgres_data:
  es_data:
